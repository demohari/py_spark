{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/06 08:49:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/06 08:49:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/04/06 08:49:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/04/06 08:49:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
      "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
      "|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n",
      "|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n",
      "|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "#SparkSession is now the entry point of Spark\n",
    "#SparkSession can also be construed as gateway to spark libraries\n",
    "\n",
    "#create instance of spark class\n",
    "spark=SparkSession.builder.appName('housing_price_model').getOrCreate()\n",
    "\n",
    "#create spark dataframe of input csv file\n",
    "df=spark.read.csv('/config/workspace/cruise_ship_info.csv'\n",
    "\t\t\t\t,inferSchema=True,header=True)\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prints structure of dataframe along with datatype\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name',\n",
       " 'Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'crew']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In our predictive model, below are the columns\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double\n"
     ]
    }
   ],
   "source": [
    "print(dict(df.dtypes)['crew'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ship_name dtype : string\n",
      "Ship_name name : 138\n",
      "Cruise_line dtype : string\n",
      "Cruise_line name : 20\n",
      "Age dtype : int\n",
      "Age name : 31\n",
      "Tonnage dtype : double\n",
      "Tonnage name : 94\n",
      "passengers dtype : double\n",
      "passengers name : 104\n",
      "length dtype : double\n",
      "length name : 80\n",
      "cabins dtype : double\n",
      "cabins name : 98\n",
      "passenger_density dtype : double\n",
      "passenger_density name : 109\n",
      "crew dtype : double\n",
      "crew name : 91\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col} dtype : {dict(df.dtypes)[col]}\" )\n",
    "    print(f\"{col} name : {df.select(col).distinct().count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0)\n",
      "\n",
      "\n",
      "Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0)\n",
      "\n",
      "\n",
      "Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0)\n",
      "\n",
      "\n",
      "Row(Ship_name='Conquest', Cruise_line='Carnival', Age=11, Tonnage=110.0, passengers=29.74, length=9.53, cabins=14.88, passenger_density=36.99, crew=19.1, cruise_cat=1.0)\n",
      "\n",
      "\n",
      "Row(Ship_name='Destiny', Cruise_line='Carnival', Age=17, Tonnage=101.353, passengers=26.42, length=8.92, cabins=13.21, passenger_density=38.36, crew=10.0, cruise_cat=1.0)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#columns identified as features are as below:\n",
    "#['Cruise_line','Age','Tonnage','passengers','length','cabins','passenger_density']\n",
    "#to work on the features, spark MLlib expects every value to be in numeric form\n",
    "#feature 'Cruise_line is string datatype\n",
    "#using StringIndexer, string type will be typecast to numeric datatype\n",
    "#import library strinindexer for typecasting\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer=StringIndexer(inputCol='Cruise_line',outputCol='cruise_cat')\n",
    "indexed=indexer.fit(df).transform(df)\n",
    "\n",
    "#above code will convert string to numeric feature and create a new dataframe\n",
    "#new dataframe contains a new feature 'cruise_cat' and can be used further\n",
    "#feature cruise_cat is now vectorized and can be used to fed to model\n",
    "for item in indexed.head(5):\n",
    "\tprint(item)\n",
    "\tprint('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[6.0,30.276999999...|3.55|\n",
      "|[6.0,30.276999999...|3.55|\n",
      "|[26.0,47.262,14.8...| 6.7|\n",
      "|[11.0,110.0,29.74...|19.1|\n",
      "|[17.0,101.353,26....|10.0|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "#creating vectors from features\n",
    "#Apache MLlib takes input if vector form\n",
    "assembler=VectorAssembler(inputCols=['Age',\n",
    "'Tonnage',\n",
    "'passengers',\n",
    "'length',\n",
    "'cabins',\n",
    "'passenger_density',\n",
    "'cruise_cat'],outputCol='features')\n",
    "output=assembler.transform(indexed)\n",
    "output.select('features','crew').show(5)\n",
    "#output as below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|              105|\n",
      "|   mean|7.885428571428579|\n",
      "| stddev|3.718629045498082|\n",
      "|    min|             0.59|\n",
      "|    max|             21.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#final data consist of features and label which is crew.\n",
    "final_data=output.select('features','crew')\n",
    "#splitting data into train and test\n",
    "train_data,test_data=final_data.randomSplit([0.7,0.3])\n",
    "train_data.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|                53|\n",
      "|   mean| 7.613396226415093|\n",
      "| stddev|3.0582303476383617|\n",
      "|    min|              0.59|\n",
      "|    max|             12.38|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/06 09:47:42 WARN Instrumentation: [7ed5f174] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features| crew|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|[5.0,86.0,21.04,9...|  8.0|  9.17188845336096|\n",
      "|[6.0,30.276999999...| 3.55| 4.123983970112089|\n",
      "|[6.0,93.0,23.94,9...|11.09|10.468096052163578|\n",
      "|[6.0,110.23899999...| 11.5|11.412815486633065|\n",
      "|[6.0,112.0,38.0,9...| 10.9|11.616966783181365|\n",
      "|[9.0,88.5,21.24,9...| 10.3| 9.497047053447822|\n",
      "|[9.0,113.0,26.74,...|12.38| 11.17448552723307|\n",
      "|[9.0,113.0,26.74,...|12.38| 11.17448552723307|\n",
      "|[9.0,116.0,26.0,9...| 11.0|10.957223665774794|\n",
      "|[10.0,81.76899999...| 8.42| 8.733591454007207|\n",
      "|[10.0,90.09,25.01...| 8.58| 9.020620781237064|\n",
      "|[11.0,90.09,25.01...| 8.48|  9.01862482102656|\n",
      "|[11.0,91.0,20.32,...| 9.99| 9.147576983141775|\n",
      "|[11.0,91.62700000...|  9.0| 9.104037957147224|\n",
      "|[11.0,108.977,26....| 12.0|10.948273887336608|\n",
      "|[12.0,2.329,0.94,...|  0.6|0.2334921547532538|\n",
      "|[12.0,25.0,3.88,5...| 2.87|2.9868182184451326|\n",
      "|[12.0,42.0,14.8,7...|  6.8| 6.641867098964483|\n",
      "|[12.0,91.0,20.32,...| 9.99| 9.145581022931271|\n",
      "|[13.0,61.0,13.8,7...|  6.0| 6.424151818676919|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import LinearRegression library\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "#creating an object of class LinearRegression\n",
    "#object takes features and label as input arguments\n",
    "LinReg=LinearRegression(featuresCol='features',labelCol='crew')\n",
    "#pass train_data to train model\n",
    "model=ship_lr.fit(train_data)\n",
    "#evaluating model trained for Rsquared error\n",
    "pred=model.evaluate(test_data)\n",
    "pred.predictions.show()\n",
    "\n",
    "#print('Rsquared Error :',ship_results.r2)\n",
    "#R2 value shows accuracy of model is 92%\n",
    "#model accuracy is very good and can be use for predictive analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of the model is : DenseVector([-0.002, -0.0001, -0.0811, 0.4768, 0.776, 0.0043, 0.0465])\n",
      "The Intercept of the model is : -1.811751\n",
      "RMSE: 0.791\n",
      "MSE: 0.625\n",
      "MAE: 0.603\n",
      "r2: 0.932\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Find out coefficient value\n",
    "coefficient = model.coefficients\n",
    "print (\"The coefficient of the model is : %a\" %coefficient)\n",
    "\n",
    "\n",
    "#Find out intercept Value\n",
    "intercept = model.intercept\n",
    "print (\"The Intercept of the model is : %f\" %intercept)\n",
    "\n",
    "#Evaluate the model using metric like Mean Absolute Error(MAE), Root Mean Square Error(RMSE) and R-Square\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluation = RegressionEvaluator(labelCol=\"crew\", predictionCol=\"prediction\")\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"rmse\"})\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[5.0,86.0,21.04,9...|\n",
      "|[6.0,30.276999999...|\n",
      "|[6.0,93.0,23.94,9...|\n",
      "|[6.0,110.23899999...|\n",
      "|[6.0,112.0,38.0,9...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing Model on unlabeled data\n",
    "#create unlabeled data from test_data\n",
    "#testing model on unlabeled data\n",
    "unlabeled_data=test_data.select('features')\n",
    "unlabeled_data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[5.0,86.0,21.04,9...|  9.17188845336096|\n",
      "|[6.0,30.276999999...| 4.123983970112089|\n",
      "|[6.0,93.0,23.94,9...|10.468096052163578|\n",
      "|[6.0,110.23899999...|11.412815486633065|\n",
      "|[6.0,112.0,38.0,9...|11.616966783181365|\n",
      "|[9.0,88.5,21.24,9...| 9.497047053447822|\n",
      "|[9.0,113.0,26.74,...| 11.17448552723307|\n",
      "|[9.0,113.0,26.74,...| 11.17448552723307|\n",
      "|[9.0,116.0,26.0,9...|10.957223665774794|\n",
      "|[10.0,81.76899999...| 8.733591454007207|\n",
      "|[10.0,90.09,25.01...| 9.020620781237064|\n",
      "|[11.0,90.09,25.01...|  9.01862482102656|\n",
      "|[11.0,91.0,20.32,...| 9.147576983141775|\n",
      "|[11.0,91.62700000...| 9.104037957147224|\n",
      "|[11.0,108.977,26....|10.948273887336608|\n",
      "|[12.0,2.329,0.94,...|0.2334921547532538|\n",
      "|[12.0,25.0,3.88,5...|2.9868182184451326|\n",
      "|[12.0,42.0,14.8,7...| 6.641867098964483|\n",
      "|[12.0,91.0,20.32,...| 9.145581022931271|\n",
      "|[13.0,61.0,13.8,7...| 6.424151818676919|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=model.transform(unlabeled_data)\n",
    "predictions.show()\n",
    "#below are the results of output from test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
