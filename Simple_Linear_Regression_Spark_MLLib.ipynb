{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yPiFdVXXvTIw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/04/06 09:42:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "23/04/06 09:42:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
            "23/04/06 09:42:09 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
            "23/04/06 09:42:09 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
            "23/04/06 09:42:09 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
          ]
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "#SparkSession is now the entry point of Spark\n",
        "#SparkSession can also be construed as gateway to spark libraries\n",
        "\n",
        "#create instance of spark class\n",
        "spark=SparkSession.builder.appName('housing_price_model').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8ugAR34okwrq"
      },
      "outputs": [],
      "source": [
        "#Loading the Student_Grades_Data.csv file, uploaded in previous step\n",
        "data = spark.read.csv('/config/workspace/Student_Grades_Data.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iVmdwnMglA-G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Time_to_Study: integer (nullable = true)\n",
            " |-- Grades: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Taking a look at data type of each column to see what data types inferSchema=TRUE paramter has set for each column\n",
        "data.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Db4upoF-l5MJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+------+\n",
            "|Time_to_Study|Grades|\n",
            "+-------------+------+\n",
            "|            1|   1.5|\n",
            "|            5|   2.7|\n",
            "|            7|   3.1|\n",
            "|            3|   2.1|\n",
            "|            2|   1.8|\n",
            "|            9|   3.9|\n",
            "|            6|   2.9|\n",
            "|           12|   4.5|\n",
            "|           11|   4.3|\n",
            "|            2|   1.8|\n",
            "|            4|   2.4|\n",
            "|            8|   3.5|\n",
            "|           13|   4.8|\n",
            "|            9|   3.9|\n",
            "|           14|   5.0|\n",
            "|           10|   4.1|\n",
            "|            6|   2.9|\n",
            "|           12|   4.5|\n",
            "|            1|   1.5|\n",
            "|            4|   2.4|\n",
            "+-------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Display first few rows of data\n",
        "data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2CTOQwcil9tS"
      },
      "outputs": [],
      "source": [
        "#Create a Feature array by omitting the last column\n",
        "feature_cols = data.columns[:-1] \n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vect_assembler = VectorAssembler(inputCols=feature_cols,outputCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EQuHqDmAmCfU"
      },
      "outputs": [],
      "source": [
        "#Utilize Assembler created above in order to add the feature column\n",
        "data_w_features = vect_assembler.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aMa82qmbmGZi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+------+--------+\n",
            "|Time_to_Study|Grades|features|\n",
            "+-------------+------+--------+\n",
            "|            1|   1.5|   [1.0]|\n",
            "|            5|   2.7|   [5.0]|\n",
            "|            7|   3.1|   [7.0]|\n",
            "|            3|   2.1|   [3.0]|\n",
            "|            2|   1.8|   [2.0]|\n",
            "|            9|   3.9|   [9.0]|\n",
            "|            6|   2.9|   [6.0]|\n",
            "|           12|   4.5|  [12.0]|\n",
            "|           11|   4.3|  [11.0]|\n",
            "|            2|   1.8|   [2.0]|\n",
            "|            4|   2.4|   [4.0]|\n",
            "|            8|   3.5|   [8.0]|\n",
            "|           13|   4.8|  [13.0]|\n",
            "|            9|   3.9|   [9.0]|\n",
            "|           14|   5.0|  [14.0]|\n",
            "|           10|   4.1|  [10.0]|\n",
            "|            6|   2.9|   [6.0]|\n",
            "|           12|   4.5|  [12.0]|\n",
            "|            1|   1.5|   [1.0]|\n",
            "|            4|   2.4|   [4.0]|\n",
            "+-------------+------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Display the data having additional column named features. Had it been multiple linear regression problem, you could see all the\n",
        "# independent variable values combined in one list\n",
        "data_w_features.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ynBgdTVImKRY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+\n",
            "|features|Grades|\n",
            "+--------+------+\n",
            "|   [1.0]|   1.5|\n",
            "|   [5.0]|   2.7|\n",
            "|   [7.0]|   3.1|\n",
            "|   [3.0]|   2.1|\n",
            "|   [2.0]|   1.8|\n",
            "|   [9.0]|   3.9|\n",
            "|   [6.0]|   2.9|\n",
            "|  [12.0]|   4.5|\n",
            "|  [11.0]|   4.3|\n",
            "|   [2.0]|   1.8|\n",
            "|   [4.0]|   2.4|\n",
            "|   [8.0]|   3.5|\n",
            "|  [13.0]|   4.8|\n",
            "|   [9.0]|   3.9|\n",
            "|  [14.0]|   5.0|\n",
            "|  [10.0]|   4.1|\n",
            "|   [6.0]|   2.9|\n",
            "|  [12.0]|   4.5|\n",
            "|   [1.0]|   1.5|\n",
            "|   [4.0]|   2.4|\n",
            "+--------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Select only Features and Label from previous dataset as we need these two entities for building machine learning model\n",
        "finalized_data = data_w_features.select(\"features\",\"Grades\")\n",
        "\n",
        "finalized_data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-ZiRjJ-mmPaE"
      },
      "outputs": [],
      "source": [
        "#Split the data into training and test model with 70% obs. going in training and 30% in testing\n",
        "train_dataset, test_dataset = finalized_data.randomSplit([0.7, 0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NgceQsNhmsIp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|summary|            Grades|\n",
            "+-------+------------------+\n",
            "|  count|                31|\n",
            "|   mean|3.0709677419354837|\n",
            "| stddev| 1.100058649462866|\n",
            "|    min|               1.5|\n",
            "|    max|               5.0|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Peek into training data\n",
        "train_dataset.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "57_Hht__mwIq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|summary|            Grades|\n",
            "+-------+------------------+\n",
            "|  count|                19|\n",
            "|   mean|3.4684210526315793|\n",
            "| stddev|1.0964856140207158|\n",
            "|    min|               1.5|\n",
            "|    max|               5.0|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Peek into test_dataset\n",
        "test_dataset.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U9K1qFA2m4ZV"
      },
      "outputs": [],
      "source": [
        "#Import Linear Regression class called LinearRegression\n",
        "from pyspark.ml.regression import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uAabd_6Xm-D6"
      },
      "outputs": [],
      "source": [
        "#Create the Linear Regression object named having feature column as features and Label column as Time_to_Study\n",
        "LinReg = LinearRegression(featuresCol=\"features\", labelCol=\"Grades\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uogUsa-SnCdF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/04/06 09:43:59 WARN Instrumentation: [c97653d1] regParam is zero, which might cause numerical instability and overfitting.\n",
            "23/04/06 09:43:59 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
            "23/04/06 09:43:59 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
            "23/04/06 09:43:59 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
          ]
        }
      ],
      "source": [
        "#Train the model on the training using fit() method.\n",
        "model = LinReg.fit(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4YfXLCdanHqZ"
      },
      "outputs": [],
      "source": [
        "#Predict the Grades using the evulate method\n",
        "pred = model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EYIleaY3nPU9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------------------+\n",
            "|features|Grades|        prediction|\n",
            "+--------+------+------------------+\n",
            "|   [1.0]|   1.5|1.5505491561746585|\n",
            "|   [2.0]|   1.8|1.8245780873292259|\n",
            "|   [2.0]|   1.8|1.8245780873292259|\n",
            "|   [4.0]|   2.4|2.3726359496383607|\n",
            "|   [5.0]|   2.7| 2.646664880792928|\n",
            "|   [6.0]|   2.9|2.9206938119474954|\n",
            "|   [7.0]|   3.1| 3.194722743102063|\n",
            "|   [7.0]|   3.1| 3.194722743102063|\n",
            "|   [8.0]|   3.5|3.4687516742566302|\n",
            "|   [8.0]|   3.5|3.4687516742566302|\n",
            "|   [8.0]|   3.5|3.4687516742566302|\n",
            "|   [9.0]|   3.9|3.7427806054111974|\n",
            "|  [10.0]|   4.1| 4.016809536565765|\n",
            "|  [11.0]|   4.3| 4.290838467720333|\n",
            "|  [12.0]|   4.5|   4.5648673988749|\n",
            "|  [12.0]|   4.5|   4.5648673988749|\n",
            "|  [13.0]|   4.8| 4.838896330029467|\n",
            "|  [14.0]|   5.0| 5.112925261184035|\n",
            "|  [14.0]|   5.0| 5.112925261184035|\n",
            "+--------+------+------------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Show the predicted Grade values along side actual Grade values\n",
        "pred.predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k4Dp0AwenTtC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The coefficient of the model is : DenseVector([0.274])\n"
          ]
        }
      ],
      "source": [
        "#Find out coefficient value\n",
        "coefficient = model.coefficients\n",
        "print (\"The coefficient of the model is : %a\" %coefficient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PGnVxBIFnYvk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Intercept of the model is : 1.276520\n"
          ]
        }
      ],
      "source": [
        "#Find out intercept Value\n",
        "intercept = model.intercept\n",
        "print (\"The Intercept of the model is : %f\" %intercept)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZXM6zY4Vnen7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.071\n",
            "MSE: 0.005\n",
            "MAE: 0.059\n",
            "r2: 0.996\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the model using metric like Mean Absolute Error(MAE), Root Mean Square Error(RMSE) and R-Square\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluation = RegressionEvaluator(labelCol=\"Grades\", predictionCol=\"prediction\")\n",
        "\n",
        "# Root Mean Square Error\n",
        "rmse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"rmse\"})\n",
        "print(\"RMSE: %.3f\" % rmse)\n",
        "\n",
        "# Mean Square Error\n",
        "mse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mae\"})\n",
        "print(\"MAE: %.3f\" % mae)\n",
        "\n",
        "# r2 - coefficient of determination\n",
        "r2 = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"r2\"})\n",
        "print(\"r2: %.3f\" %r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LTh1VjsknmOa"
      },
      "outputs": [],
      "source": [
        "#Create Unlabeled dataset  to contain only feature column\n",
        "unlabeled_dataset = test_dataset.select('features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "q0lsatZ-o7dq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|features|\n",
            "+--------+\n",
            "|   [1.0]|\n",
            "|   [2.0]|\n",
            "|   [2.0]|\n",
            "|   [4.0]|\n",
            "|   [5.0]|\n",
            "|   [6.0]|\n",
            "|   [7.0]|\n",
            "|   [7.0]|\n",
            "|   [8.0]|\n",
            "|   [8.0]|\n",
            "|   [8.0]|\n",
            "|   [9.0]|\n",
            "|  [10.0]|\n",
            "|  [11.0]|\n",
            "|  [12.0]|\n",
            "|  [12.0]|\n",
            "|  [13.0]|\n",
            "|  [14.0]|\n",
            "|  [14.0]|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Display the content of unlabeled_dataset\n",
        "unlabeled_dataset.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wQ4y6cuLpCda"
      },
      "outputs": [],
      "source": [
        "#Predict the model output for fresh & unseen test data using transform() method\n",
        "new_predictions = model.transform(unlabeled_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7pM_V96XpJIO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------------------+\n",
            "|features|        prediction|\n",
            "+--------+------------------+\n",
            "|   [1.0]|1.5505491561746585|\n",
            "|   [2.0]|1.8245780873292259|\n",
            "|   [2.0]|1.8245780873292259|\n",
            "|   [4.0]|2.3726359496383607|\n",
            "|   [5.0]| 2.646664880792928|\n",
            "|   [6.0]|2.9206938119474954|\n",
            "|   [7.0]| 3.194722743102063|\n",
            "|   [7.0]| 3.194722743102063|\n",
            "|   [8.0]|3.4687516742566302|\n",
            "|   [8.0]|3.4687516742566302|\n",
            "|   [8.0]|3.4687516742566302|\n",
            "|   [9.0]|3.7427806054111974|\n",
            "|  [10.0]| 4.016809536565765|\n",
            "|  [11.0]| 4.290838467720333|\n",
            "|  [12.0]|   4.5648673988749|\n",
            "|  [12.0]|   4.5648673988749|\n",
            "|  [13.0]| 4.838896330029467|\n",
            "|  [14.0]| 5.112925261184035|\n",
            "|  [14.0]| 5.112925261184035|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Display the new prediction values\n",
        "new_predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMpOj9MtpdjE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Simple_Linear_Regression_Spark_MLLib.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
